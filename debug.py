#!/usr/bin/env python3
"""T world í¬ë¡¤ëŸ¬ ë””ë²„ê¹… ë„êµ¬"""
import time
import json
import argparse
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import os
from config import DATA_DIR
from src.logger import setup_logger

logger = setup_logger(__name__)

class TworldDebugger:
    """T world í˜ì´ì§€ ë””ë²„ê±°"""
    
    def __init__(self):
        self.driver = None
    
    def setup_driver(self, headless=False):
        """ë“œë¼ì´ë²„ ì„¤ì • - Selenium 4.6+ ìë™ ë“œë¼ì´ë²„ ê´€ë¦¬"""
        options = Options()
        if not headless:
            options.add_argument('--window-size=1920,1080')
        else:
            options.add_argument('--headless')
        
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        
        try:
            # Selenium 4.6+ ìë™ ë“œë¼ì´ë²„ ê´€ë¦¬
            self.driver = webdriver.Chrome(options=options)
            logger.info("Chrome ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ (Selenium Manager ì‚¬ìš©)")
        except Exception as e:
            logger.error(f"Chrome ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            logger.info("Chrome ë¸Œë¼ìš°ì €ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            raise
    
    def analyze_page(self, url):
        """í˜ì´ì§€ êµ¬ì¡° ë¶„ì„"""
        logger.info(f"í˜ì´ì§€ ë¶„ì„ ì‹œì‘: {url}")
        
        try:
            self.setup_driver(headless=False)
            self.driver.get(url)
            time.sleep(5)
            
            # ê¸°ë³¸ ì •ë³´
            print("\n" + "="*50)
            print("ğŸ“‹ í˜ì´ì§€ ê¸°ë³¸ ì •ë³´")
            print("="*50)
            print(f"ì œëª©: {self.driver.title}")
            print(f"URL: {self.driver.current_url}")
            
            # JavaScript ë³€ìˆ˜ í™•ì¸
            self._check_js_variables()
            
            # HTML êµ¬ì¡° ë¶„ì„
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            self._analyze_html_structure(soup)
            
            # ë°ì´í„° íŒ¨í„´ ì°¾ê¸°
            self._find_data_patterns(soup)
            
            # ìŠ¤í¬ë¦°ìƒ· ë° HTML ì €ì¥
            self._save_debug_files()
            
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            if self.driver:
                self.driver.quit()
    
    def _check_js_variables(self):
        """JavaScript ì „ì—­ ë³€ìˆ˜ í™•ì¸"""
        print("\n" + "="*50)
        print("ğŸ”§ JavaScript ì „ì—­ ë³€ìˆ˜")
        print("="*50)
        
        js_code = """
        var results = {};
        var keywords = ['support', 'fee', 'disclosure', 'price', 'plan', 'product'];
        
        for (var prop in window) {
            for (var keyword of keywords) {
                if (prop.toLowerCase().includes(keyword)) {
                    try {
                        var value = window[prop];
                        var type = typeof value;
                        results[prop] = {
                            type: type,
                            preview: type === 'object' ? JSON.stringify(value).substring(0, 100) : String(value).substring(0, 100)
                        };
                    } catch(e) {}
                }
            }
        }
        return results;
        """
        
        try:
            variables = self.driver.execute_script(js_code)
            if variables:
                for name, info in variables.items():
                    print(f"\në³€ìˆ˜ëª…: {name}")
                    print(f"íƒ€ì…: {info['type']}")
                    print(f"ë¯¸ë¦¬ë³´ê¸°: {info['preview']}...")
            else:
                print("ê´€ë ¨ ì „ì—­ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"JavaScript ë³€ìˆ˜ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def _analyze_html_structure(self, soup):
        """HTML êµ¬ì¡° ë¶„ì„"""
        print("\n" + "="*50)
        print("ğŸ—ï¸ HTML êµ¬ì¡° ë¶„ì„")
        print("="*50)
        
        # ì£¼ìš” í´ë˜ìŠ¤ ì°¾ê¸°
        print("\nğŸ“Œ ê³µì‹œì§€ì›ê¸ˆ ê´€ë ¨ í´ë˜ìŠ¤:")
        classes_found = set()
        
        for tag in soup.find_all(class_=True):
            classes = tag.get('class', [])
            for cls in classes:
                cls_lower = cls.lower()
                if any(keyword in cls_lower for keyword in 
                      ['support', 'fee', 'disclosure', 'price', 'ê³µì‹œ', 'ì§€ì›ê¸ˆ']):
                    classes_found.add(cls)
        
        for cls in sorted(classes_found):
            print(f"  .{cls}")
        
        # í…Œì´ë¸” êµ¬ì¡° í™•ì¸
        tables = soup.find_all('table')
        if tables:
            print(f"\nğŸ“Š í…Œì´ë¸” ìˆ˜: {len(tables)}")
            for i, table in enumerate(tables[:3]):
                headers = [th.get_text(strip=True) for th in table.find_all('th')]
                if headers:
                    print(f"  í…Œì´ë¸” {i+1} í—¤ë”: {headers}")
    
    def _find_data_patterns(self, soup):
        """ë°ì´í„° íŒ¨í„´ ì°¾ê¸°"""
        print("\n" + "="*50)
        print("ğŸ’° ê¸ˆì•¡ ì •ë³´")
        print("="*50)
        
        import re
        text = soup.get_text()
        
        # ê¸ˆì•¡ íŒ¨í„´
        prices = re.findall(r'([0-9]{1,3}(?:,[0-9]{3})*)\s*ì›', text)
        unique_prices = sorted(set(prices), 
                             key=lambda x: int(x.replace(',', '')), 
                             reverse=True)
        
        print("\në°œê²¬ëœ ê¸ˆì•¡ (ìƒìœ„ 10ê°œ):")
        for i, price in enumerate(unique_prices[:10], 1):
            print(f"  {i}. {price}ì›")
        
        # ìš”ê¸ˆì œ íŒ¨í„´
        print("\nğŸ“± ìš”ê¸ˆì œ ì •ë³´:")
        plans = re.findall(r'((?:5G|LTE)[^\s]*(?:\s*[ê°€-í£]+)*(?:\s*[0-9]+)?)', text)
        unique_plans = sorted(set([p.strip() for p in plans if len(p.strip()) < 30]))
        
        for plan in unique_plans[:10]:
            print(f"  - {plan}")
    
    def _save_debug_files(self):
        """ë””ë²„ê·¸ íŒŒì¼ ì €ì¥"""
        print("\n" + "="*50)
        print("ğŸ’¾ ë””ë²„ê·¸ íŒŒì¼ ì €ì¥")
        print("="*50)
        
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        
        # ìŠ¤í¬ë¦°ìƒ·
        screenshot_path = os.path.join(DATA_DIR, f'debug_screenshot_{timestamp}.png')
        self.driver.save_screenshot(screenshot_path)
        print(f"âœ“ ìŠ¤í¬ë¦°ìƒ·: {screenshot_path}")
        
        # HTML ì†ŒìŠ¤
        html_path = os.path.join(DATA_DIR, f'debug_source_{timestamp}.html')
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(self.driver.page_source)
        print(f"âœ“ HTML ì†ŒìŠ¤: {html_path}")
        
        # í˜ì´ì§€ ì •ë³´ JSON
        info = {
            'url': self.driver.current_url,
            'title': self.driver.title,
            'timestamp': timestamp,
            'window_size': self.driver.get_window_size(),
            'cookies': self.driver.get_cookies()
        }
        
        json_path = os.path.join(DATA_DIR, f'debug_info_{timestamp}.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)
        print(f"âœ“ í˜ì´ì§€ ì •ë³´: {json_path}")
    
    def find_api_calls(self, url):
        """API í˜¸ì¶œ ì°¾ê¸°"""
        logger.info("API ì—”ë“œí¬ì¸íŠ¸ íƒìƒ‰ ì‹œì‘")
        
        try:
            from seleniumwire import webdriver as sw_webdriver
            
            options = {
                'disable_encoding': True,
                'request_storage': 'memory'
            }
            
            chrome_options = Options()
            chrome_options.add_argument('--window-size=1920,1080')
            
            driver = sw_webdriver.Chrome(
                seleniumwire_options=options,
                options=chrome_options
            )
            
            try:
                driver.get(url)
                time.sleep(10)
                
                print("\n" + "="*50)
                print("ğŸŒ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„")
                print("="*50)
                
                api_calls = []
                
                for request in driver.requests:
                    if request.response and request.response.status_code == 200:
                        url_lower = request.url.lower()
                        
                        # API ê´€ë ¨ ìš”ì²­ í•„í„°
                        if any(keyword in url_lower for keyword in 
                              ['api', 'ajax', 'json', 'support', 'fee', 'disclosure']):
                            
                            api_calls.append({
                                'url': request.url,
                                'method': request.method,
                                'status': request.response.status_code,
                                'content_type': request.response.headers.get('Content-Type', ''),
                                'size': len(request.response.body) if request.response.body else 0
                            })
                
                if api_calls:
                    print(f"\në°œê²¬ëœ API í˜¸ì¶œ: {len(api_calls)}ê°œ")
                    for i, call in enumerate(api_calls, 1):
                        print(f"\n[{i}] {call['method']} {call['url']}")
                        print(f"    ìƒíƒœ: {call['status']}")
                        print(f"    íƒ€ì…: {call['content_type']}")
                        print(f"    í¬ê¸°: {call['size']} bytes")
                else:
                    print("\nAPI í˜¸ì¶œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                logger.error(f"API íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            finally:
                driver.quit()
                
        except ImportError:
            logger.error("selenium-wireê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            logger.info("API íƒìƒ‰ì„ ìœ„í•´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install selenium-wire")

def main():
    parser = argparse.ArgumentParser(description='T world í¬ë¡¤ëŸ¬ ë””ë²„ê¹… ë„êµ¬')
    parser.add_argument('command', choices=['analyze', 'api'], 
                       help='ì‹¤í–‰í•  ëª…ë ¹ (analyze: í˜ì´ì§€ ë¶„ì„, api: API ì°¾ê¸°)')
    parser.add_argument('--url', type=str, 
                       default="https://m.shop.tworld.co.kr/notice?modelNwType=5G&saleMonth=24&dcMthdCd=10&prodId=NA00007790",
                       help='ë¶„ì„í•  URL')
    
    args = parser.parse_args()
    
    debugger = TworldDebugger()
    
    if args.command == 'analyze':
        debugger.analyze_page(args.url)
    elif args.command == 'api':
        debugger.find_api_calls(args.url)

if __name__ == "__main__":
    main()