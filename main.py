#!/usr/bin/env python3
import argparse
import sys
import os
from datetime import datetime
from src.tworld_crawler import TworldCrawler
from src.tworld_complete_crawler import TworldCompleteCrawler
from src.logger import setup_logger
from config import OUTPUT_FORMATS

logger = setup_logger(__name__)

def print_banner():
    """ë°°ë„ˆ ì¶œë ¥"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     T world ê³µì‹œì§€ì›ê¸ˆ í¬ë¡¤ëŸ¬ v2.0      â•‘
â•‘         Fee Crawler for T world          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def print_usage_examples():
    """ì‚¬ìš© ì˜ˆì‹œ ì¶œë ¥"""
    examples = """
ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
  
  # ê¸°ë³¸ í¬ë¡¤ë§ (ë‹¨ì¼ í˜ì´ì§€)
  python3 main.py
  
  # íŠ¹ì • URL í¬ë¡¤ë§
  python3 main.py --url "https://..."
  
  # ì™„ì „ í¬ë¡¤ë§ (ëª¨ë“  ëª¨ë¸/ìš”ê¸ˆì œ)
  python3 main.py --complete
  
  # CSVë§Œ ì €ì¥
  python3 main.py --output csv
  
  # ë””ë²„ê·¸ ëª¨ë“œ
  python3 main.py --debug
  
  # ë¸Œë¼ìš°ì € í‘œì‹œ ëª¨ë“œ
  python3 main.py --no-headless
    """
    print(examples)

def main():
    print_banner()
    
    parser = argparse.ArgumentParser(
        description='T world ê³µì‹œì§€ì›ê¸ˆ í¬ë¡¤ëŸ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        add_help=True
    )
    
    # í¬ë¡¤ë§ ëª¨ë“œ ê·¸ë£¹
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        '--url', 
        type=str, 
        help='í¬ë¡¤ë§í•  íŠ¹ì • URL'
    )
    mode_group.add_argument(
        '--complete',
        action='store_true',
        help='ì „ì²´ ëª¨ë¸/ìš”ê¸ˆì œ ì¡°í•© í¬ë¡¤ë§ (ì™„ì „ í¬ë¡¤ë§ ëª¨ë“œ)'
    )
    
    # ì¶œë ¥ ì˜µì…˜
    parser.add_argument(
        '--output', 
        choices=OUTPUT_FORMATS + ['all'], 
        default='all',
        help='ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸ê°’: all)'
    )
    
    # ì¶”ê°€ ì˜µì…˜
    parser.add_argument(
        '--screenshot',
        action='store_true',
        help='ìŠ¤í¬ë¦°ìƒ· ì €ì¥'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸ ë¡œê·¸ ì¶œë ¥)'
    )
    
    parser.add_argument(
        '--no-headless',
        action='store_true',
        help='ë¸Œë¼ìš°ì € í™”ë©´ í‘œì‹œ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ë¹„í™œì„±í™”)'
    )
    
    parser.add_argument(
        '--help-examples',
        action='store_true',
        help='ì‚¬ìš© ì˜ˆì‹œ ë³´ê¸°'
    )
    
    args = parser.parse_args()
    
    # ì‚¬ìš© ì˜ˆì‹œ ì¶œë ¥
    if args.help_examples:
        print_usage_examples()
        return 0
    
    # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
    if args.debug:
        import logging
        logging.getLogger().setLevel(logging.DEBUG)
        logger.debug("ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”")
    
    # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì„¤ì •
    if args.no_headless:
        os.environ['HEADLESS'] = 'False'
        logger.info("ë¸Œë¼ìš°ì € í™”ë©´ í‘œì‹œ ëª¨ë“œ")
    
    try:
        # ì™„ì „ í¬ë¡¤ë§ ëª¨ë“œ (ëª¨ë“  ëª¨ë¸/ìš”ê¸ˆì œ ì¡°í•©)
        if args.complete:
            logger.info("ì™„ì „ í¬ë¡¤ë§ ëª¨ë“œ ì‹œì‘...")
            logger.info("ëª¨ë“  ì œì¡°ì‚¬, ëª¨ë“  ëª¨ë¸, ëª¨ë“  ìš”ê¸ˆì œ ì¡°í•©ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.")
            logger.info("ì´ ì‘ì—…ì€ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            confirm = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
            if confirm.lower() != 'y':
                logger.info("í¬ë¡¤ë§ ì·¨ì†Œë¨")
                return 0
            
            crawler = TworldCompleteCrawler()
            crawler.fetch_complete_data()
            
            if crawler.data:
                saved_files = {}
                
                # ì¶œë ¥ í˜•ì‹ì— ë”°ë¼ ì €ì¥
                if args.output in ['csv', 'all']:
                    csv_file = crawler.save_to_csv(f"tworld_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
                    if csv_file:
                        saved_files['CSV'] = csv_file
                
                if args.output in ['json', 'all']:
                    json_file = crawler.save_to_json(f"tworld_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
                    if json_file:
                        saved_files['JSON'] = json_file
                
                if args.output in ['excel', 'all']:
                    # ì‹œíŠ¸ë³„ Excel ì €ì¥
                    excel_file = crawler.save_to_excel_with_sheets()
                    if excel_file:
                        saved_files['Excel'] = excel_file
                
                # ê²°ê³¼ ìš”ì•½
                print(crawler.get_summary())
                
                # ì €ì¥ëœ íŒŒì¼ ëª©ë¡
                if saved_files:
                    print("\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
                    for format_type, filepath in saved_files.items():
                        print(f"  - {format_type}: {filepath}")
                
                # ìƒìœ„ 10ê°œ ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
                print("\nğŸ“Š ë°ì´í„° ìƒ˜í”Œ (ê³µì‹œì§€ì›ê¸ˆ ìƒìœ„ 10ê°œ):")
                sorted_data = sorted(crawler.data, key=lambda x: x.get('public_support_fee', 0), reverse=True)
                for i, item in enumerate(sorted_data[:10], 1):
                    print(f"\n[{i}] {item['device_name']}")
                    if 'plan_name' in item:
                        print(f"    ìš”ê¸ˆì œ: {item['plan_name']}")
                    print(f"    ì œì¡°ì‚¬: {item.get('manufacturer', 'Unknown')}")
                    print(f"    ê³µì‹œì§€ì›ê¸ˆ: {item['public_support_fee']:,}ì›")
                    print(f"    ì¶”ê°€ì§€ì›ê¸ˆ: {item['additional_support_fee']:,}ì›")
                    print(f"    ì´ ì§€ì›ê¸ˆ: {item['total_support_fee']:,}ì›")
                
                logger.info("\nâœ… ì™„ì „ í¬ë¡¤ë§ ì™„ë£Œ!")
                return 0
            else:
                logger.error("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                logger.info("ë””ë²„ê·¸ ëª¨ë“œ(--debug)ë¡œ ì‹¤í–‰í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                return 1
        
        # ë‹¨ì¼ í˜ì´ì§€ í¬ë¡¤ë§ ëª¨ë“œ (ê¸°ë³¸)
        else:
            logger.info("í¬ë¡¤ë§ ì‹œì‘...")
            crawler = TworldCrawler()
            
            # URLì´ ì§€ì •ë˜ì—ˆìœ¼ë©´ í•´ë‹¹ URL, ì•„ë‹ˆë©´ ê¸°ë³¸ URL
            crawler.fetch_data(url=args.url)
            
            # ìŠ¤í¬ë¦°ìƒ·
            if args.screenshot:
                screenshot_file = crawler.take_screenshot(f"tworld_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
                if screenshot_file:
                    logger.info(f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_file}")
            
            # ê²°ê³¼ ì €ì¥
            if crawler.data:
                saved_files = []
                
                if args.output in ['csv', 'all']:
                    filepath = crawler.save_to_csv()
                    if filepath:
                        saved_files.append(filepath)
                
                if args.output in ['excel', 'all']:
                    filepath = crawler.save_to_excel()
                    if filepath:
                        saved_files.append(filepath)
                
                if args.output in ['json', 'all']:
                    filepath = crawler.save_to_json()
                    if filepath:
                        saved_files.append(filepath)
                
                # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
                print(crawler.get_summary())
                
                if saved_files:
                    print("\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
                    for file in saved_files:
                        print(f"  - {file}")
                
                # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
                print("\nğŸ“Š ë°ì´í„° ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ):")
                for i, item in enumerate(crawler.data[:5], 1):
                    print(f"\n[{i}] {item['device_name']}")
                    if 'plan_name' in item:
                        print(f"    ìš”ê¸ˆì œ: {item.get('plan_name', 'Unknown')}")
                    print(f"    ê³µì‹œì§€ì›ê¸ˆ: {item['public_support_fee']:,}ì›")
                    print(f"    ì¶”ê°€ì§€ì›ê¸ˆ: {item['additional_support_fee']:,}ì›")
                    print(f"    ì´ ì§€ì›ê¸ˆ: {item['total_support_fee']:,}ì›")
                    if 'release_price' in item and item['release_price'] > 0:
                        print(f"    ì¶œì‹œê°€ê²©: {item['release_price']:,}ì›")
                    if 'date' in item:
                        print(f"    ê³µì‹œì¼: {item['date']}")
                
                logger.info("\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")
                return 0
            else:
                logger.error("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                logger.info("ë‹¤ìŒì„ í™•ì¸í•´ë³´ì„¸ìš”:")
                logger.info("  1. ì¸í„°ë„· ì—°ê²° ìƒíƒœ")
                logger.info("  2. T world ì‚¬ì´íŠ¸ ì ‘ì† ê°€ëŠ¥ ì—¬ë¶€")
                logger.info("  3. --debug ì˜µì…˜ìœ¼ë¡œ ìƒì„¸ ë¡œê·¸ í™•ì¸")
                return 1
            
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        return 130
    except ImportError as e:
        logger.error(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
        logger.error("í•„ìš”í•œ ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        logger.error("  pip install -r requirements.txt")
        return 1
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        logger.error("ë””ë²„ê·¸ ëª¨ë“œ(--debug)ë¡œ ì‹¤í–‰í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return 1

if __name__ == "__main__":
    try:
        sys.exit(main())
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)
